{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Shahz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello Mr. umair, how are you doing today?', 'The weather is great!', 'and Python is awesome.', 'The sky is blue.', 'You have to eat pizza.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "TEXT = \"Hello Mr. umair, how are you doing today? The weather is great! and Python is awesome. The sky is blue. You have to eat pizza.\"\n",
    "print(sent_tokenize(TEXT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Mr. umair, how are you doing today?',\n",
       " 'The weather is great, and Python is awesome.',\n",
       " 'The sky is blue.',\n",
       " 'You have to eat pizza.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tokens = sent_tokenize(TEXT)\n",
    "new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Mr.', 'umair', ',', 'how', 'are', 'you', 'doing', 'today', '?', 'The', 'weather', 'is', 'great', '!', 'and', 'Python', 'is', 'awesome', '.', 'The', 'sky', 'is', 'blue', '.', 'You', 'have', 'to', 'eat', 'pizza', '.']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(TEXT)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Text: Hello Mr. umair , how are you doing...>\n"
     ]
    }
   ],
   "source": [
    "from nltk.text import Text\n",
    "t = Text(tokens)\n",
    "print (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.count('is')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'is': 3, '.': 3, ',': 2, 'The': 2, 'Hello': 1, 'Mr.': 1, 'umair': 1, 'how': 1, 'are': 1, 'you': 1, ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ء',\n",
       " 'ءَ',\n",
       " 'آ',\n",
       " 'آب',\n",
       " 'آذار',\n",
       " 'آض',\n",
       " 'آمينَ',\n",
       " 'آناء',\n",
       " 'آنفا',\n",
       " 'آه',\n",
       " 'آها',\n",
       " 'آهاً',\n",
       " 'آهٍ',\n",
       " 'آهِ',\n",
       " 'آي',\n",
       " 'أ',\n",
       " 'أبدا',\n",
       " 'أبريل',\n",
       " 'أبو',\n",
       " 'أبٌ',\n",
       " 'أجل',\n",
       " 'أجمع',\n",
       " 'أحد',\n",
       " 'أخبر',\n",
       " 'أخذ',\n",
       " 'أخو',\n",
       " 'أخٌ',\n",
       " 'أربع',\n",
       " 'أربعاء',\n",
       " 'أربعة',\n",
       " 'أربعمئة',\n",
       " 'أربعمائة',\n",
       " 'أرى',\n",
       " 'أسكن',\n",
       " 'أصبح',\n",
       " 'أصلا',\n",
       " 'أضحى',\n",
       " 'أطعم',\n",
       " 'أعطى',\n",
       " 'أعلم',\n",
       " 'أغسطس',\n",
       " 'أف',\n",
       " 'أفريل',\n",
       " 'أفعل به',\n",
       " 'أفٍّ',\n",
       " 'أقبل',\n",
       " 'أقل',\n",
       " 'أكتوبر',\n",
       " 'أكثر',\n",
       " 'أل',\n",
       " 'ألا',\n",
       " 'ألف',\n",
       " 'ألفى',\n",
       " 'أم',\n",
       " 'أما',\n",
       " 'أمام',\n",
       " 'أمامك',\n",
       " 'أمامكَ',\n",
       " 'أمد',\n",
       " 'أمس',\n",
       " 'أمسى',\n",
       " 'أمّا',\n",
       " 'أن',\n",
       " 'أنا',\n",
       " 'أنبأ',\n",
       " 'أنت',\n",
       " 'أنتم',\n",
       " 'أنتما',\n",
       " 'أنتن',\n",
       " 'أنتِ',\n",
       " 'أنشأ',\n",
       " 'أنى',\n",
       " 'أنًّ',\n",
       " 'أنّى',\n",
       " 'أهلا',\n",
       " 'أو',\n",
       " 'أوت',\n",
       " 'أوشك',\n",
       " 'أول',\n",
       " 'أولئك',\n",
       " 'أولاء',\n",
       " 'أولالك',\n",
       " 'أوه',\n",
       " 'أوّهْ',\n",
       " 'أى',\n",
       " 'أي',\n",
       " 'أيا',\n",
       " 'أيار',\n",
       " 'أيضا',\n",
       " 'أيلول',\n",
       " 'أين',\n",
       " 'أينما',\n",
       " 'أيها',\n",
       " 'أيّ',\n",
       " 'أيّان',\n",
       " 'أُفٍّ',\n",
       " 'ؤ',\n",
       " 'إحدى',\n",
       " 'إذ',\n",
       " 'إذا',\n",
       " 'إذاً',\n",
       " 'إذما',\n",
       " 'إذن',\n",
       " 'إزاء',\n",
       " 'إلا',\n",
       " 'إلى',\n",
       " 'إليك',\n",
       " 'إليكم',\n",
       " 'إليكما',\n",
       " 'إليكن',\n",
       " 'إليكنّ',\n",
       " 'إليكَ',\n",
       " 'إلَيْكَ',\n",
       " 'إلّا',\n",
       " 'إما',\n",
       " 'إمّا',\n",
       " 'إن',\n",
       " 'إنا',\n",
       " 'إنما',\n",
       " 'إنه',\n",
       " 'إنَّ',\n",
       " 'إى',\n",
       " 'إي',\n",
       " 'إياك',\n",
       " 'إياكم',\n",
       " 'إياكما',\n",
       " 'إياكن',\n",
       " 'إيانا',\n",
       " 'إياه',\n",
       " 'إياها',\n",
       " 'إياهم',\n",
       " 'إياهما',\n",
       " 'إياهن',\n",
       " 'إياي',\n",
       " 'إيه',\n",
       " 'إيهٍ',\n",
       " 'ئ',\n",
       " 'ا',\n",
       " 'ابتدأ',\n",
       " 'اتخذ',\n",
       " 'اثنا',\n",
       " 'اثنان',\n",
       " 'اثني',\n",
       " 'اثنين',\n",
       " 'اخلولق',\n",
       " 'اربعون',\n",
       " 'اربعين',\n",
       " 'ارتدّ',\n",
       " 'استحال',\n",
       " 'الآن',\n",
       " 'الألاء',\n",
       " 'الألى',\n",
       " 'التي',\n",
       " 'الذي',\n",
       " 'الذين',\n",
       " 'اللائي',\n",
       " 'اللاتي',\n",
       " 'اللتان',\n",
       " 'اللتيا',\n",
       " 'اللتين',\n",
       " 'اللذان',\n",
       " 'اللذين',\n",
       " 'اللواتي',\n",
       " 'انبرى',\n",
       " 'انقلب',\n",
       " 'ب',\n",
       " 'بؤسا',\n",
       " 'بئس',\n",
       " 'باء',\n",
       " 'بات',\n",
       " 'بخ',\n",
       " 'بخٍ',\n",
       " 'بس',\n",
       " 'بسّ',\n",
       " 'بضع',\n",
       " 'بطآن',\n",
       " 'بعد',\n",
       " 'بعدا',\n",
       " 'بعض',\n",
       " 'بغتة',\n",
       " 'بك',\n",
       " 'بكم',\n",
       " 'بكما',\n",
       " 'بكن',\n",
       " 'بل',\n",
       " 'بلى',\n",
       " 'بما',\n",
       " 'بماذا',\n",
       " 'بمن',\n",
       " 'بنا',\n",
       " 'به',\n",
       " 'بها',\n",
       " 'بهم',\n",
       " 'بهما',\n",
       " 'بهن',\n",
       " 'بي',\n",
       " 'بيد',\n",
       " 'بين',\n",
       " 'بَسْ',\n",
       " 'بَلْهَ',\n",
       " 'ة',\n",
       " 'ت',\n",
       " 'تاء',\n",
       " 'تارة',\n",
       " 'تاسع',\n",
       " 'تانِ',\n",
       " 'تانِك',\n",
       " 'تبدّل',\n",
       " 'تجاه',\n",
       " 'تحت',\n",
       " 'تحوّل',\n",
       " 'تخذ',\n",
       " 'ترك',\n",
       " 'تسع',\n",
       " 'تسعة',\n",
       " 'تسعمئة',\n",
       " 'تسعمائة',\n",
       " 'تسعون',\n",
       " 'تسعين',\n",
       " 'تشرين',\n",
       " 'تعسا',\n",
       " 'تعلَّم',\n",
       " 'تفعلان',\n",
       " 'تفعلون',\n",
       " 'تفعلين',\n",
       " 'تلقاء',\n",
       " 'تلك',\n",
       " 'تلكم',\n",
       " 'تلكما',\n",
       " 'تموز',\n",
       " 'ته',\n",
       " 'تي',\n",
       " 'تين',\n",
       " 'تينك',\n",
       " 'تَيْنِ',\n",
       " 'تِه',\n",
       " 'تِي',\n",
       " 'ث',\n",
       " 'ثاء',\n",
       " 'ثالث',\n",
       " 'ثامن',\n",
       " 'ثان',\n",
       " 'ثاني',\n",
       " 'ثلاث',\n",
       " 'ثلاثاء',\n",
       " 'ثلاثة',\n",
       " 'ثلاثمئة',\n",
       " 'ثلاثمائة',\n",
       " 'ثلاثون',\n",
       " 'ثلاثين',\n",
       " 'ثم',\n",
       " 'ثمان',\n",
       " 'ثمانمئة',\n",
       " 'ثمانون',\n",
       " 'ثماني',\n",
       " 'ثمانية',\n",
       " 'ثمانين',\n",
       " 'ثمة',\n",
       " 'ثمنمئة',\n",
       " 'ثمَّ',\n",
       " 'ثمّ',\n",
       " 'ثمّة',\n",
       " 'ج',\n",
       " 'جانفي',\n",
       " 'جعل',\n",
       " 'جلل',\n",
       " 'جمعة',\n",
       " 'جميع',\n",
       " 'جنيه',\n",
       " 'جوان',\n",
       " 'جويلية',\n",
       " 'جير',\n",
       " 'جيم',\n",
       " 'ح',\n",
       " 'حاء',\n",
       " 'حادي',\n",
       " 'حار',\n",
       " 'حاشا',\n",
       " 'حاي',\n",
       " 'حبذا',\n",
       " 'حبيب',\n",
       " 'حتى',\n",
       " 'حجا',\n",
       " 'حدَث',\n",
       " 'حرى',\n",
       " 'حزيران',\n",
       " 'حسب',\n",
       " 'حقا',\n",
       " 'حمدا',\n",
       " 'حمو',\n",
       " 'حمٌ',\n",
       " 'حيث',\n",
       " 'حيثما',\n",
       " 'حين',\n",
       " 'حيَّ',\n",
       " 'حَذارِ',\n",
       " 'خ',\n",
       " 'خاء',\n",
       " 'خاصة',\n",
       " 'خال',\n",
       " 'خامس',\n",
       " 'خبَّر',\n",
       " 'خلا',\n",
       " 'خلافا',\n",
       " 'خلف',\n",
       " 'خمس',\n",
       " 'خمسة',\n",
       " 'خمسمئة',\n",
       " 'خمسمائة',\n",
       " 'خمسون',\n",
       " 'خمسين',\n",
       " 'خميس',\n",
       " 'د',\n",
       " 'دال',\n",
       " 'درهم',\n",
       " 'درى',\n",
       " 'دواليك',\n",
       " 'دولار',\n",
       " 'دون',\n",
       " 'دونك',\n",
       " 'ديسمبر',\n",
       " 'دينار',\n",
       " 'ذ',\n",
       " 'ذا',\n",
       " 'ذات',\n",
       " 'ذاك',\n",
       " 'ذال',\n",
       " 'ذان',\n",
       " 'ذانك',\n",
       " 'ذانِ',\n",
       " 'ذلك',\n",
       " 'ذلكم',\n",
       " 'ذلكما',\n",
       " 'ذلكن',\n",
       " 'ذه',\n",
       " 'ذهب',\n",
       " 'ذو',\n",
       " 'ذوا',\n",
       " 'ذواتا',\n",
       " 'ذواتي',\n",
       " 'ذي',\n",
       " 'ذيت',\n",
       " 'ذين',\n",
       " 'ذينك',\n",
       " 'ذَيْنِ',\n",
       " 'ذِه',\n",
       " 'ذِي',\n",
       " 'ر',\n",
       " 'رأى',\n",
       " 'راء',\n",
       " 'رابع',\n",
       " 'راح',\n",
       " 'رجع',\n",
       " 'رزق',\n",
       " 'رويدك',\n",
       " 'ريال',\n",
       " 'ريث',\n",
       " 'رُبَّ',\n",
       " 'ز',\n",
       " 'زاي',\n",
       " 'زعم',\n",
       " 'زود',\n",
       " 'س',\n",
       " 'ساء',\n",
       " 'سابع',\n",
       " 'سادس',\n",
       " 'سبت',\n",
       " 'سبتمبر',\n",
       " 'سبحان',\n",
       " 'سبع',\n",
       " 'سبعة',\n",
       " 'سبعمئة',\n",
       " 'سبعمائة',\n",
       " 'سبعون',\n",
       " 'سبعين',\n",
       " 'ست',\n",
       " 'ستة',\n",
       " 'ستمئة',\n",
       " 'ستمائة',\n",
       " 'ستون',\n",
       " 'ستين',\n",
       " 'سحقا',\n",
       " 'سرا',\n",
       " 'سرعان',\n",
       " 'سقى',\n",
       " 'سمعا',\n",
       " 'سنتيم',\n",
       " 'سوف',\n",
       " 'سوى',\n",
       " 'سين',\n",
       " 'ش',\n",
       " 'شباط',\n",
       " 'شبه',\n",
       " 'شتان',\n",
       " 'شتانَ',\n",
       " 'شرع',\n",
       " 'شمال',\n",
       " 'شيكل',\n",
       " 'شين',\n",
       " 'شَتَّانَ',\n",
       " 'ص',\n",
       " 'صاد',\n",
       " 'صار',\n",
       " 'صباح',\n",
       " 'صبر',\n",
       " 'صبرا',\n",
       " 'صدقا',\n",
       " 'صراحة',\n",
       " 'صهٍ',\n",
       " 'صهْ',\n",
       " 'ض',\n",
       " 'ضاد',\n",
       " 'ضحوة',\n",
       " 'ط',\n",
       " 'طاء',\n",
       " 'طاق',\n",
       " 'طالما',\n",
       " 'طرا',\n",
       " 'طفق',\n",
       " 'طَق',\n",
       " 'ظ',\n",
       " 'ظاء',\n",
       " 'ظلّ',\n",
       " 'ظنَّ',\n",
       " 'ع',\n",
       " 'عاد',\n",
       " 'عاشر',\n",
       " 'عامة',\n",
       " 'عجبا',\n",
       " 'عدا',\n",
       " 'عدَّ',\n",
       " 'عسى',\n",
       " 'عشر',\n",
       " 'عشرة',\n",
       " 'عشرون',\n",
       " 'عشرين',\n",
       " 'عل',\n",
       " 'علق',\n",
       " 'علم',\n",
       " 'على',\n",
       " 'عليك',\n",
       " 'عليه',\n",
       " 'علًّ',\n",
       " 'عما',\n",
       " 'عن',\n",
       " 'عند',\n",
       " 'عوض',\n",
       " 'عيانا',\n",
       " 'عين',\n",
       " 'عَدَسْ',\n",
       " 'غ',\n",
       " 'غادر',\n",
       " 'غالبا',\n",
       " 'غدا',\n",
       " 'غداة',\n",
       " 'غير',\n",
       " 'غين',\n",
       " 'ف',\n",
       " 'فإذا',\n",
       " 'فإن',\n",
       " 'فاء',\n",
       " 'فبراير',\n",
       " 'فرادى',\n",
       " 'فضلا',\n",
       " 'فلا',\n",
       " 'فلان',\n",
       " 'فلس',\n",
       " 'فمن',\n",
       " 'فو',\n",
       " 'فوق',\n",
       " 'في',\n",
       " 'فيفري',\n",
       " 'فيم',\n",
       " 'فيما',\n",
       " 'فيه',\n",
       " 'فيها',\n",
       " 'ق',\n",
       " 'قاطبة',\n",
       " 'قاف',\n",
       " 'قام',\n",
       " 'قبل',\n",
       " 'قد',\n",
       " 'قرش',\n",
       " 'قطّ',\n",
       " 'قلما',\n",
       " 'ك',\n",
       " 'كأن',\n",
       " 'كأنما',\n",
       " 'كأنّ',\n",
       " 'كأي',\n",
       " 'كأين',\n",
       " 'كأيّ',\n",
       " 'كأيّن',\n",
       " 'كاد',\n",
       " 'كاف',\n",
       " 'كان',\n",
       " 'كانون',\n",
       " 'كثيرا',\n",
       " 'كذا',\n",
       " 'كذلك',\n",
       " 'كرب',\n",
       " 'كسا',\n",
       " 'كل',\n",
       " 'كلا',\n",
       " 'كلاهما',\n",
       " 'كلتا',\n",
       " 'كلما',\n",
       " 'كليكما',\n",
       " 'كليهما',\n",
       " 'كلَّا',\n",
       " 'كلّما',\n",
       " 'كم',\n",
       " 'كما',\n",
       " 'كن',\n",
       " 'كى',\n",
       " 'كي',\n",
       " 'كيت',\n",
       " 'كيف',\n",
       " 'كيفما',\n",
       " 'كِخ',\n",
       " 'ل',\n",
       " 'لئن',\n",
       " 'لا',\n",
       " 'لا سيما',\n",
       " 'لات',\n",
       " 'لاسيما',\n",
       " 'لام',\n",
       " 'لبيك',\n",
       " 'لدن',\n",
       " 'لدى',\n",
       " 'لست',\n",
       " 'لستم',\n",
       " 'لستما',\n",
       " 'لستن',\n",
       " 'لسن',\n",
       " 'لسنا',\n",
       " 'لعل',\n",
       " 'لعلَّ',\n",
       " 'لعمر',\n",
       " 'لك',\n",
       " 'لكم',\n",
       " 'لكما',\n",
       " 'لكن',\n",
       " 'لكنما',\n",
       " 'لكنَّ',\n",
       " 'لكي',\n",
       " 'لكيلا',\n",
       " 'لم',\n",
       " 'لما',\n",
       " 'لمّا',\n",
       " 'لن',\n",
       " 'لنا',\n",
       " 'له',\n",
       " 'لها',\n",
       " 'لهم',\n",
       " 'لهما',\n",
       " 'لهن',\n",
       " 'لو',\n",
       " 'لولا',\n",
       " 'لوما',\n",
       " 'لي',\n",
       " 'ليت',\n",
       " 'ليرة',\n",
       " 'ليس',\n",
       " 'ليسا',\n",
       " 'ليست',\n",
       " 'ليستا',\n",
       " 'ليسوا',\n",
       " 'م',\n",
       " 'مئة',\n",
       " 'مئتان',\n",
       " 'ما',\n",
       " 'ما أفعله',\n",
       " 'ما انفك',\n",
       " 'ما برح',\n",
       " 'مائة',\n",
       " 'مادام',\n",
       " 'ماذا',\n",
       " 'مارس',\n",
       " 'مازال',\n",
       " 'مافتئ',\n",
       " 'ماي',\n",
       " 'مايو',\n",
       " 'متى',\n",
       " 'مثل',\n",
       " 'مذ',\n",
       " 'مرّة',\n",
       " 'مساء',\n",
       " 'مع',\n",
       " 'معاذ',\n",
       " 'مكانكم',\n",
       " 'مكانكما',\n",
       " 'مكانكنّ',\n",
       " 'مكانَك',\n",
       " 'مليم',\n",
       " 'مما',\n",
       " 'ممن',\n",
       " 'من',\n",
       " 'منذ',\n",
       " 'منه',\n",
       " 'منها',\n",
       " 'مه',\n",
       " 'مهما',\n",
       " 'ميم',\n",
       " 'ن',\n",
       " 'نا',\n",
       " 'نبَّا',\n",
       " 'نحن',\n",
       " 'نحو',\n",
       " 'نعم',\n",
       " 'نفس',\n",
       " 'نوفمبر',\n",
       " 'نون',\n",
       " 'نيسان',\n",
       " 'نيف',\n",
       " 'نَخْ',\n",
       " 'نَّ',\n",
       " 'ه',\n",
       " 'هؤلاء',\n",
       " 'ها',\n",
       " 'هاء',\n",
       " 'هاتان',\n",
       " 'هاته',\n",
       " 'هاتي',\n",
       " 'هاتين',\n",
       " 'هاك',\n",
       " 'هاكَ',\n",
       " 'هاهنا',\n",
       " 'هبّ',\n",
       " 'هذا',\n",
       " 'هذان',\n",
       " 'هذه',\n",
       " 'هذي',\n",
       " 'هذين',\n",
       " 'هكذا',\n",
       " 'هل',\n",
       " 'هلا',\n",
       " 'هللة',\n",
       " 'هلم',\n",
       " 'هلّا',\n",
       " 'هم',\n",
       " 'هما',\n",
       " 'همزة',\n",
       " 'هن',\n",
       " 'هنا',\n",
       " 'هناك',\n",
       " 'هنالك',\n",
       " 'هو',\n",
       " 'هي',\n",
       " 'هيا',\n",
       " 'هيت',\n",
       " 'هيهات',\n",
       " 'هيّا',\n",
       " 'هَؤلاء',\n",
       " 'هَاتانِ',\n",
       " 'هَاتَيْنِ',\n",
       " 'هَاتِه',\n",
       " 'هَاتِي',\n",
       " 'هَجْ',\n",
       " 'هَذا',\n",
       " 'هَذانِ',\n",
       " 'هَذَيْنِ',\n",
       " 'هَذِه',\n",
       " 'هَذِي',\n",
       " 'هَيْهات',\n",
       " 'و',\n",
       " 'وإذ',\n",
       " 'وإذا',\n",
       " 'وإن',\n",
       " 'وا',\n",
       " 'واحد',\n",
       " 'والذي',\n",
       " 'والذين',\n",
       " 'واهاً',\n",
       " 'واو',\n",
       " 'وجد',\n",
       " 'وراءَك',\n",
       " 'ورد',\n",
       " 'ولا',\n",
       " 'ولكن',\n",
       " 'ولو',\n",
       " 'وما',\n",
       " 'ومن',\n",
       " 'وهب',\n",
       " 'وهو',\n",
       " 'وَيْ',\n",
       " 'وُشْكَانَ',\n",
       " 'ى',\n",
       " 'ي',\n",
       " 'يا',\n",
       " 'ياء',\n",
       " 'يفعلان',\n",
       " 'يفعلون',\n",
       " 'يمين',\n",
       " 'ين',\n",
       " 'يناير',\n",
       " 'يوان',\n",
       " 'يورو',\n",
       " 'يوليو',\n",
       " 'يونيو',\n",
       " 'ّأيّان'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "set(stopwords.words('arabic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'the', 'stop', 'words', 'filtration', '.']\n",
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "# filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "\n",
    "#or\n",
    "filtered_sentence = []\n",
    "\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        filtered_sentence.append(w)\n",
    "\n",
    "print(word_tokens)\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new sentences without stop words are: ['Hello', 'going', 'waiting', '.', 'What', 'time', 'going', '?']\n"
     ]
    }
   ],
   "source": [
    "#Creating a method to filter stopwords\n",
    "sample_sentence = \"Hello what is going on he was waiting for her. What is time now where are you going?\"\n",
    "stop_words_sentences = set(stopwords.words('english'))\n",
    "sample_tokens = word_tokenize(sample_sentence)\n",
    "new_filtered_sentences = []\n",
    "for i in sample_tokens:\n",
    "    if i not in stop_words_sentences:\n",
    "        new_filtered_sentences.append(i)\n",
    "print(f\"The new sentences without stop words are: {new_filtered_sentences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# List the file identifiers for stop word sets in NLTK\n",
    "stopword_fileids = stopwords.fileids()\n",
    "\n",
    "# Print the file identifiers\n",
    "print(stopword_fileids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['arabic',\n",
       " 'azerbaijani',\n",
       " 'basque',\n",
       " 'bengali',\n",
       " 'catalan',\n",
       " 'chinese',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'greek',\n",
       " 'hebrew',\n",
       " 'hinglish',\n",
       " 'hungarian',\n",
       " 'indonesian',\n",
       " 'italian',\n",
       " 'kazakh',\n",
       " 'nepali',\n",
       " 'norwegian',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'slovene',\n",
       " 'spanish',\n",
       " 'swedish',\n",
       " 'tajik',\n",
       " 'turkish']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This method is use to create id's of languages \n",
    "stopwords.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'إذ\\nإذا\\nإذما\\nإذن\\nأف\\nأقل\\nأكثر\\nألا\\nإلا\\nالتي\\nالذي\\nالذين\\nاللاتي\\nاللائي\\nاللتان\\nاللتيا\\nاللتين\\nاللذان\\nاللذين\\nاللواتي\\nإلى\\nإليك\\nإليكم\\nإليكما\\nإليكن\\nأم\\nأما\\nأما\\nإما\\nأن\\nإن\\nإنا\\nأنا\\nأنت\\nأنتم\\nأنتما\\nأنتن\\nإنما\\nإنه\\nأنى\\nأنى\\nآه\\nآها\\nأو\\nأولاء\\nأولئك\\nأوه\\nآي\\nأي\\nأيها\\nإي\\nأين\\nأين\\nأينما\\nإيه\\nبخ\\nبس\\nبعد\\nبعض\\nبك\\nبكم\\nبكم\\nبكما\\nبكن\\nبل\\nبلى\\nبما\\nبماذا\\nبمن\\nبنا\\nبه\\nبها\\nبهم\\nبهما\\nبهن\\nبي\\nبين\\nبيد\\nتلك\\nتلكم\\nتلكما\\nته\\nتي\\nتين\\nتينك\\nثم\\nثمة\\nحاشا\\nحبذا\\nحتى\\nحيث\\nحيثما\\nحين\\nخلا\\nدون\\nذا\\nذات\\nذاك\\nذان\\nذانك\\nذلك\\nذلكم\\nذلكما\\nذلكن\\nذه\\nذو\\nذوا\\nذواتا\\nذواتي\\nذي\\nذين\\nذينك\\nريث\\nسوف\\nسوى\\nشتان\\nعدا\\nعسى\\nعل\\nعلى\\nعليك\\nعليه\\nعما\\nعن\\nعند\\nغير\\nفإذا\\nفإن\\nفلا\\nفمن\\nفي\\nفيم\\nفيما\\nفيه\\nفيها\\nقد\\nكأن\\nكأنما\\nكأي\\nكأين\\nكذا\\nكذلك\\nكل\\nكلا\\nكلاهما\\nكلتا\\nكلما\\nكليكما\\nكليهما\\nكم\\nكم\\nكما\\nكي\\nكيت\\nكيف\\nكيفما\\nلا\\nلاسيما\\nلدى\\nلست\\nلستم\\nلستما\\nلستن\\nلسن\\nلسنا\\nلعل\\nلك\\nلكم\\nلكما\\nلكن\\nلكنما\\nلكي\\nلكيلا\\nلم\\nلما\\nلن\\nلنا\\nله\\nلها\\nلهم\\nلهما\\nلهن\\nلو\\nلولا\\nلوما\\nلي\\nلئن\\nليت\\nليس\\nليسا\\nليست\\nليستا\\nليسوا\\nما\\nماذا\\nمتى\\nمذ\\nمع\\nمما\\nممن\\nمن\\nمنه\\nمنها\\nمنذ\\nمه\\nمهما\\nنحن\\nنحو\\nنعم\\nها\\nهاتان\\nهاته\\nهاتي\\nهاتين\\nهاك\\nهاهنا\\nهذا\\nهذان\\nهذه\\nهذي\\nهذين\\nهكذا\\nهل\\nهلا\\nهم\\nهما\\nهن\\nهنا\\nهناك\\nهنالك\\nهو\\nهؤلاء\\nهي\\nهيا\\nهيت\\nهيهات\\nوالذي\\nوالذين\\nوإذ\\nوإذا\\nوإن\\nولا\\nولكن\\nولو\\nوما\\nومن\\nوهو\\nيا\\nأبٌ\\nأخٌ\\nحمٌ\\nفو\\nأنتِ\\nيناير\\nفبراير\\nمارس\\nأبريل\\nمايو\\nيونيو\\nيوليو\\nأغسطس\\nسبتمبر\\nأكتوبر\\nنوفمبر\\nديسمبر\\nجانفي\\nفيفري\\nمارس\\nأفريل\\nماي\\nجوان\\nجويلية\\nأوت\\nكانون\\nشباط\\nآذار\\nنيسان\\nأيار\\nحزيران\\nتموز\\nآب\\nأيلول\\nتشرين\\nدولار\\nدينار\\nريال\\nدرهم\\nليرة\\nجنيه\\nقرش\\nمليم\\nفلس\\nهللة\\nسنتيم\\nيورو\\nين\\nيوان\\nشيكل\\nواحد\\nاثنان\\nثلاثة\\nأربعة\\nخمسة\\nستة\\nسبعة\\nثمانية\\nتسعة\\nعشرة\\nأحد\\nاثنا\\nاثني\\nإحدى\\nثلاث\\nأربع\\nخمس\\nست\\nسبع\\nثماني\\nتسع\\nعشر\\nثمان\\nسبت\\nأحد\\nاثنين\\nثلاثاء\\nأربعاء\\nخميس\\nجمعة\\nأول\\nثان\\nثاني\\nثالث\\nرابع\\nخامس\\nسادس\\nسابع\\nثامن\\nتاسع\\nعاشر\\nحادي\\nأ\\nب\\nت\\nث\\nج\\nح\\nخ\\nد\\nذ\\nر\\nز\\nس\\nش\\nص\\nض\\nط\\nظ\\nع\\nغ\\nف\\nق\\nك\\nل\\nم\\nن\\nه\\nو\\nي\\nء\\nى\\nآ\\nؤ\\nئ\\nأ\\nة\\nألف\\nباء\\nتاء\\nثاء\\nجيم\\nحاء\\nخاء\\nدال\\nذال\\nراء\\nزاي\\nسين\\nشين\\nصاد\\nضاد\\nطاء\\nظاء\\nعين\\nغين\\nفاء\\nقاف\\nكاف\\nلام\\nميم\\nنون\\nهاء\\nواو\\nياء\\nهمزة\\nي\\nنا\\nك\\nكن\\nه\\nإياه\\nإياها\\nإياهما\\nإياهم\\nإياهن\\nإياك\\nإياكما\\nإياكم\\nإياك\\nإياكن\\nإياي\\nإيانا\\nأولالك\\nتانِ\\nتانِك\\nتِه\\nتِي\\nتَيْنِ\\nثمّ\\nثمّة\\nذانِ\\nذِه\\nذِي\\nذَيْنِ\\nهَؤلاء\\nهَاتانِ\\nهَاتِه\\nهَاتِي\\nهَاتَيْنِ\\nهَذا\\nهَذانِ\\nهَذِه\\nهَذِي\\nهَذَيْنِ\\nالألى\\nالألاء\\nأل\\nأنّى\\nأيّ\\nّأيّان\\nأنّى\\nأيّ\\nّأيّان\\nذيت\\nكأيّ\\nكأيّن\\nبضع\\nفلان\\nوا\\nآمينَ\\nآهِ\\nآهٍ\\nآهاً\\nأُفٍّ\\nأُفٍّ\\nأفٍّ\\nأمامك\\nأمامكَ\\nأوّهْ\\nإلَيْكَ\\nإلَيْكَ\\nإليكَ\\nإليكنّ\\nإيهٍ\\nبخٍ\\nبسّ\\nبَسْ\\nبطآن\\nبَلْهَ\\nحاي\\nحَذارِ\\nحيَّ\\nحيَّ\\nدونك\\nرويدك\\nسرعان\\nشتانَ\\nشَتَّانَ\\nصهْ\\nصهٍ\\nطاق\\nطَق\\nعَدَسْ\\nكِخ\\nمكانَك\\nمكانَك\\nمكانَك\\nمكانكم\\nمكانكما\\nمكانكنّ\\nنَخْ\\nهاكَ\\nهَجْ\\nهلم\\nهيّا\\nهَيْهات\\nوا\\nواهاً\\nوراءَك\\nوُشْكَانَ\\nوَيْ\\nيفعلان\\nتفعلان\\nيفعلون\\nتفعلون\\nتفعلين\\nاتخذ\\nألفى\\nتخذ\\nترك\\nتعلَّم\\nجعل\\nحجا\\nحبيب\\nخال\\nحسب\\nخال\\nدرى\\nرأى\\nزعم\\nصبر\\nظنَّ\\nعدَّ\\nعلم\\nغادر\\nذهب\\nوجد\\nورد\\nوهب\\nأسكن\\nأطعم\\nأعطى\\nرزق\\nزود\\nسقى\\nكسا\\nأخبر\\nأرى\\nأعلم\\nأنبأ\\nحدَث\\nخبَّر\\nنبَّا\\nأفعل به\\nما أفعله\\nبئس\\nساء\\nطالما\\nقلما\\nلات\\nلكنَّ\\nءَ\\nأجل\\nإذاً\\nأمّا\\nإمّا\\nإنَّ\\nأنًّ\\nأى\\nإى\\nأيا\\nب\\nثمَّ\\nجلل\\nجير\\nرُبَّ\\nس\\nعلًّ\\nف\\nكأنّ\\nكلَّا\\nكى\\nل\\nلات\\nلعلَّ\\nلكنَّ\\nلكنَّ\\nم\\nنَّ\\nهلّا\\nوا\\nأل\\nإلّا\\nت\\nك\\nلمّا\\nن\\nه\\nو\\nا\\nي\\nتجاه\\nتلقاء\\nجميع\\nحسب\\nسبحان\\nشبه\\nلعمر\\nمثل\\nمعاذ\\nأبو\\nأخو\\nحمو\\nفو\\nمئة\\nمئتان\\nثلاثمئة\\nأربعمئة\\nخمسمئة\\nستمئة\\nسبعمئة\\nثمنمئة\\nتسعمئة\\nمائة\\nثلاثمائة\\nأربعمائة\\nخمسمائة\\nستمائة\\nسبعمائة\\nثمانمئة\\nتسعمائة\\nعشرون\\nثلاثون\\nاربعون\\nخمسون\\nستون\\nسبعون\\nثمانون\\nتسعون\\nعشرين\\nثلاثين\\nاربعين\\nخمسين\\nستين\\nسبعين\\nثمانين\\nتسعين\\nبضع\\nنيف\\nأجمع\\nجميع\\nعامة\\nعين\\nنفس\\nلا سيما\\nأصلا\\nأهلا\\nأيضا\\nبؤسا\\nبعدا\\nبغتة\\nتعسا\\nحقا\\nحمدا\\nخلافا\\nخاصة\\nدواليك\\nسحقا\\nسرا\\nسمعا\\nصبرا\\nصدقا\\nصراحة\\nطرا\\nعجبا\\nعيانا\\nغالبا\\nفرادى\\nفضلا\\nقاطبة\\nكثيرا\\nلبيك\\nمعاذ\\nأبدا\\nإزاء\\nأصلا\\nالآن\\nأمد\\nأمس\\nآنفا\\nآناء\\nأنّى\\nأول\\nأيّان\\nتارة\\nثمّ\\nثمّة\\nحقا\\nصباح\\nمساء\\nضحوة\\nعوض\\nغدا\\nغداة\\nقطّ\\nكلّما\\nلدن\\nلمّا\\nمرّة\\nقبل\\nخلف\\nأمام\\nفوق\\nتحت\\nيمين\\nشمال\\nارتدّ\\nاستحال\\nأصبح\\nأضحى\\nآض\\nأمسى\\nانقلب\\nبات\\nتبدّل\\nتحوّل\\nحار\\nرجع\\nراح\\nصار\\nظلّ\\nعاد\\nغدا\\nكان\\nما انفك\\nما برح\\nمادام\\nمازال\\nمافتئ\\nابتدأ\\nأخذ\\nاخلولق\\nأقبل\\nانبرى\\nأنشأ\\nأوشك\\nجعل\\nحرى\\nشرع\\nطفق\\nعلق\\nقام\\nكرب\\nكاد\\nهبّ'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.raw('arabic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'إذ إذا إذما إذن أف أقل أكثر ألا إلا التي الذي الذين اللاتي اللائي اللتان اللتيا اللتين اللذان اللذين اللواتي إلى إليك إليكم إليكما إليكن أم أما أما إما أن إن إنا أنا أنت أنتم أنتما أنتن إنما إنه أنى أنى آه آها أو أولاء أولئك أوه آي أي أيها إي أين أين أينما إيه بخ بس بعد بعض بك بكم بكم بكما بكن بل بلى بما بماذا بمن بنا به بها بهم بهما بهن بي بين بيد تلك تلكم تلكما ته تي تين تينك ثم ثمة حاشا حبذا حتى حيث حيثما حين خلا دون ذا ذات ذاك ذان ذانك ذلك ذلكم ذلكما ذلكن ذه ذو ذوا ذواتا ذواتي ذي ذين ذينك ريث سوف سوى شتان عدا عسى عل على عليك عليه عما عن عند غير فإذا فإن فلا فمن في فيم فيما فيه فيها قد كأن كأنما كأي كأين كذا كذلك كل كلا كلاهما كلتا كلما كليكما كليهما كم كم كما كي كيت كيف كيفما لا لاسيما لدى لست لستم لستما لستن لسن لسنا لعل لك لكم لكما لكن لكنما لكي لكيلا لم لما لن لنا له لها لهم لهما لهن لو لولا لوما لي لئن ليت ليس ليسا ليست ليستا ليسوا ما ماذا متى مذ مع مما ممن من منه منها منذ مه مهما نحن نحو نعم ها هاتان هاته هاتي هاتين هاك هاهنا هذا هذان هذه هذي هذين هكذا هل هلا هم هما هن هنا هناك هنالك هو هؤلاء هي هيا هيت هيهات والذي والذين وإذ وإذا وإن ولا ولكن ولو وما ومن وهو يا أبٌ أخٌ حمٌ فو أنتِ يناير فبراير مارس أبريل مايو يونيو يوليو أغسطس سبتمبر أكتوبر نوفمبر ديسمبر جانفي فيفري مارس أفريل ماي جوان جويلية أوت كانون شباط آذار نيسان أيار حزيران تموز آب أيلول تشرين دولار دينار ريال درهم ليرة جنيه قرش مليم فلس هللة سنتيم يورو ين يوان شيكل واحد اثنان ثلاثة أربعة خمسة ستة سبعة ثمانية تسعة عشرة أحد اثنا اثني إحدى ثلاث أربع خمس ست سبع ثماني تسع عشر ثمان سبت أحد اثنين ثلاثاء أربعاء خميس جمعة أول ثان ثاني ثالث رابع خامس سادس سابع ثامن تاسع عاشر حادي أ ب ت ث ج ح خ د ذ ر ز س ش ص ض ط ظ ع غ ف ق ك ل م ن ه و ي ء ى آ ؤ ئ أ ة ألف باء تاء ثاء جيم حاء خاء دال ذال راء زاي سين شين صاد ضاد طاء ظاء عين غين فاء قاف كاف لام ميم نون هاء واو ياء همزة ي نا ك كن ه إياه إياها إياهما إياهم إياهن إياك إياكما إياكم إياك إياكن إياي إيانا أولالك تانِ تانِك تِه تِي تَيْنِ ثمّ ثمّة ذانِ ذِه ذِي ذَيْنِ هَؤلاء هَاتانِ هَاتِه هَاتِي هَاتَيْنِ هَذا هَذانِ هَذِه هَذِي هَذَيْنِ الألى الألاء أل أنّى أيّ ّأيّان أنّى أيّ ّأيّان ذيت كأيّ كأيّن بضع فلان وا آمينَ آهِ آهٍ آهاً أُفٍّ أُفٍّ أفٍّ أمامك أمامكَ أوّهْ إلَيْكَ إلَيْكَ إليكَ إليكنّ إيهٍ بخٍ بسّ بَسْ بطآن بَلْهَ حاي حَذارِ حيَّ حيَّ دونك رويدك سرعان شتانَ شَتَّانَ صهْ صهٍ طاق طَق عَدَسْ كِخ مكانَك مكانَك مكانَك مكانكم مكانكما مكانكنّ نَخْ هاكَ هَجْ هلم هيّا هَيْهات وا واهاً وراءَك وُشْكَانَ وَيْ يفعلان تفعلان يفعلون تفعلون تفعلين اتخذ ألفى تخذ ترك تعلَّم جعل حجا حبيب خال حسب خال درى رأى زعم صبر ظنَّ عدَّ علم غادر ذهب وجد ورد وهب أسكن أطعم أعطى رزق زود سقى كسا أخبر أرى أعلم أنبأ حدَث خبَّر نبَّا أفعل به ما أفعله بئس ساء طالما قلما لات لكنَّ ءَ أجل إذاً أمّا إمّا إنَّ أنًّ أى إى أيا ب ثمَّ جلل جير رُبَّ س علًّ ف كأنّ كلَّا كى ل لات لعلَّ لكنَّ لكنَّ م نَّ هلّا وا أل إلّا ت ك لمّا ن ه و ا ي تجاه تلقاء جميع حسب سبحان شبه لعمر مثل معاذ أبو أخو حمو فو مئة مئتان ثلاثمئة أربعمئة خمسمئة ستمئة سبعمئة ثمنمئة تسعمئة مائة ثلاثمائة أربعمائة خمسمائة ستمائة سبعمائة ثمانمئة تسعمائة عشرون ثلاثون اربعون خمسون ستون سبعون ثمانون تسعون عشرين ثلاثين اربعين خمسين ستين سبعين ثمانين تسعين بضع نيف أجمع جميع عامة عين نفس لا سيما أصلا أهلا أيضا بؤسا بعدا بغتة تعسا حقا حمدا خلافا خاصة دواليك سحقا سرا سمعا صبرا صدقا صراحة طرا عجبا عيانا غالبا فرادى فضلا قاطبة كثيرا لبيك معاذ أبدا إزاء أصلا الآن أمد أمس آنفا آناء أنّى أول أيّان تارة ثمّ ثمّة حقا صباح مساء ضحوة عوض غدا غداة قطّ كلّما لدن لمّا مرّة قبل خلف أمام فوق تحت يمين شمال ارتدّ استحال أصبح أضحى آض أمسى انقلب بات تبدّل تحوّل حار رجع راح صار ظلّ عاد غدا كان ما انفك ما برح مادام مازال مافتئ ابتدأ أخذ اخلولق أقبل انبرى أنشأ أوشك جعل حرى شرع طفق علق قام كرب كاد هبّ'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.raw('arabic').replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Testing out what is given'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\"\"\"Testing out what is given\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python\n",
      "python\n",
      "python\n",
      "python\n"
     ]
    }
   ],
   "source": [
    "example_words = [\"python\",\"pythoner\",\"pythoning\",\"pythoned\"]\n",
    "for w in example_words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text = \"It is Went to by worse pythoner womens while you are pythoning with python. All pythoners have pythoned poorly at least once. there are foxes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n",
      "is\n",
      "went\n",
      "to\n",
      "by\n",
      "wors\n",
      "python\n",
      "women\n",
      "while\n",
      "you\n",
      "are\n",
      "python\n",
      "with\n",
      "python\n",
      ".\n",
      "all\n",
      "python\n",
      "have\n",
      "python\n",
      "poorli\n",
      "at\n",
      "least\n",
      "onc\n",
      ".\n",
      "there\n",
      "are\n",
      "fox\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(new_text)\n",
    "\n",
    "for w in words:\n",
    "    print(ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Shahz/nltk_data'\n    - 'c:\\\\Users\\\\Shahz\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\nltk_data'\n    - 'c:\\\\Users\\\\Shahz\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Shahz\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Shahz\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Shahz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\corpus\\util.py:84\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mzip_name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     85\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Shahz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Shahz/nltk_data'\n    - 'c:\\\\Users\\\\Shahz\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\nltk_data'\n    - 'c:\\\\Users\\\\Shahz\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Shahz\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Shahz\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32md:\\Semester 2\\Programming For AI(python)\\Practice\\NLP(NLTK)\\NLTK.ipynb Cell 21\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semester%202/Programming%20For%20AI%28python%29/Practice/NLP%28NLTK%29/NLTK.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m words \u001b[39m=\u001b[39m word_tokenize(new_text)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Semester%202/Programming%20For%20AI%28python%29/Practice/NLP%28NLTK%29/NLTK.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m words:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Semester%202/Programming%20For%20AI%28python%29/Practice/NLP%28NLTK%29/NLTK.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mprint\u001b[39m(wnl\u001b[39m.\u001b[39;49mlemmatize(w))\n",
      "File \u001b[1;32mc:\\Users\\Shahz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\stem\\wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize\u001b[39m(\u001b[39mself\u001b[39m, word: \u001b[39mstr\u001b[39m, pos: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m     34\u001b[0m     \u001b[39m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     lemmas \u001b[39m=\u001b[39m wn\u001b[39m.\u001b[39;49m_morphy(word, pos)\n\u001b[0;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmin\u001b[39m(lemmas, key\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m) \u001b[39mif\u001b[39;00m lemmas \u001b[39melse\u001b[39;00m word\n",
      "File \u001b[1;32mc:\\Users\\Shahz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\corpus\\util.py:121\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    119\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mLazyCorpusLoader object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m__bases__\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 121\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__load()\n\u001b[0;32m    122\u001b[0m \u001b[39m# This looks circular, but its not, since __load() changes our\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m# __class__ to something new:\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, attr)\n",
      "File \u001b[1;32mc:\\Users\\Shahz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\corpus\\util.py:86\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     84\u001b[0m             root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfind(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubdir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mzip_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n\u001b[1;32m---> 86\u001b[0m             \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m     88\u001b[0m \u001b[39m# Load the corpus.\u001b[39;00m\n\u001b[0;32m     89\u001b[0m corpus \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__reader_cls(root, \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__kwargs)\n",
      "File \u001b[1;32mc:\\Users\\Shahz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\corpus\\util.py:81\u001b[0m, in \u001b[0;36mLazyCorpusLoader.__load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     80\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 81\u001b[0m         root \u001b[39m=\u001b[39m nltk\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mfind(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msubdir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__name\u001b[39m}\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     82\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     83\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Shahz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\nltk\\data.py:583\u001b[0m, in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    581\u001b[0m sep \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m*\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m*\u001b[39m \u001b[39m70\u001b[39m\n\u001b[0;32m    582\u001b[0m resource_not_found \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mmsg\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00msep\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 583\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mLookupError\u001b[39;00m(resource_not_found)\n",
      "\u001b[1;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - 'C:\\\\Users\\\\Shahz/nltk_data'\n    - 'c:\\\\Users\\\\Shahz\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\nltk_data'\n    - 'c:\\\\Users\\\\Shahz\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\share\\\\nltk_data'\n    - 'c:\\\\Users\\\\Shahz\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python310\\\\lib\\\\nltk_data'\n    - 'C:\\\\Users\\\\Shahz\\\\AppData\\\\Roaming\\\\nltk_data'\n    - 'C:\\\\nltk_data'\n    - 'D:\\\\nltk_data'\n    - 'E:\\\\nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "words = word_tokenize(new_text)\n",
    "\n",
    "for w in words:\n",
    "    print(wnl.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the women run in the fog pass bunni work as comput scientist .\n",
      "the wom run in the fog pass bunny work as comput sci .\n",
      "the women run in the fog pass bunni work as comput scientist .\n"
     ]
    }
   ],
   "source": [
    "#Different stemmers\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "text = list(nltk.word_tokenize(\"The women running in the fog passed bunnies working as computer scientists.\"))\n",
    "\n",
    "snowball = SnowballStemmer('english')\n",
    "lancaster = LancasterStemmer()\n",
    "porter = PorterStemmer()\n",
    "\n",
    "for stemmer in (snowball, lancaster, porter):\n",
    "    stemmed_text = [stemmer.stem(t) for t in text]\n",
    "    print (\" \".join(stemmed_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eagle', 'fly', 'midnight']\n"
     ]
    }
   ],
   "source": [
    "#Typical normalization of text for use as features in machine learning models looks something like this:\n",
    "import string\n",
    "lemmatizer  = WordNetLemmatizer()\n",
    "stopwords   = set(nltk.corpus.stopwords.words('english'))\n",
    "punctuation = string.punctuation\n",
    "def normalize(text):\n",
    "    for token in nltk.word_tokenize(text):\n",
    "        token = token.lower()\n",
    "        token = lemmatizer.lemmatize(token)\n",
    "        if token not in stopwords and token not in punctuation:\n",
    "            yield token\n",
    "\n",
    "print (list(normalize(\"The EAGLE flies at midnight.\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The women running in the four passed bundles working as computer scientists.\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "       \n",
    "text = \"The women runnning in the foug passed bunnies working as computer scientists.\"               # Reading the file\n",
    "textBlb = TextBlob(text)            # Making our first textblob\n",
    "textCorrected = textBlb.correct()   # Correcting the text\n",
    "print(textCorrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punctuation = string.punctuation\n",
    "print(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
